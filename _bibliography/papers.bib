---
---

@string{aps = {American Physical Society,}}


@article{tuli_telepresence_2020,
	abbr={SORO}, 
	title = {Telepresence {Mobile} {Robots} {Design} and {Control} for {Social} {Interaction}},
	issn = {1875-4805},
	url = {https://doi.org/10.1007/s12369-020-00676-3},
	doi = {10.1007/s12369-020-00676-3},
	abstract = {Human–robot interaction has extended its application horizon to simplify how human beings interact with each other through a remotely controlled telepresence robot. The fast growth of communication technologies such as 4G and 5G has elevated the potential to establish stable audio–video-data transmission. However, human–robot physical interactions are still challenging regarding maneuverability, controllability, stability, drive layout, and autonomy. Hence, this paper presents a systematic design and control approach based on the customer’s needs and expectations of telepresence mobile robots for social interactions. A system model and controller design are developed using the Lagrangian method and linear quadratic regulator, respectively, for different scenarios such as flat surface, inclined surface, and yaw (steering). The robot system is capable of traveling uphill (30\$\${\textasciicircum}\{{\textbackslash}circ \}\$\$∘) and has a variable height (600–1200 mm). The robot is advantageous in developing countries to fill the skill gaps as well as for sharing knowledge and expertise using a virtual and mobile physical presence.},
	language = {en},
	urldate = {2020-09-14},
	journal = {International Journal of Social Robotics},
	author = {Tuli, Tadele Belay and Terefe, Tesfaye Olana and Rashid, Md Mamun Ur},
	month = jul,
	year = {2020},
	bibtex_show = True,
	selected = True,
	

}

@article{tuli_real-time_2019,
	abbr={ECSA},
	title = {Real-{Time} {Motion} {Tracking} for {Humans} and {Robots} in a {Collaborative} {Assembly} {Task}},
	volume = {42},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/2504-3900/42/1/48},
	doi = {10.3390/ecsa-6-06636},
	abstract = {Human-robot collaboration combines the extended capabilities of humans and robots to create a more inclusive and human-centered production system in the future. However, human safety is the primary concern for manufacturing industries. Therefore, real-time motion tracking is necessary to identify if the human worker body parts enter the restricted working space solely dedicated to the robot. Tracking these motions using decentralized and different tracking systems requires a generic model controller and consistent motion exchanging formats. In this work, our task is to investigate a concept for a unified real-time motion tracking for human-robot collaboration. In this regard, a low cost and game-based motion tracking system, e.g., HTC Vive, is utilized to capture human motion by mapping into a digital human model in the Unity3D environment. In this context, the human model is described using a biomechanical model that comprises joint segments defined by position and orientation. Concerning robot motion tracking, a unified robot description format is used to describe the kinematic trees. Finally, a concept of assembly operation that involves snap joining is simulated to analyze the performance of the system in real-time capability. The distribution of joint variables in spatial-space and time-space is analyzed. The results suggest that real-time tracking in human-robot collaborative assembly environments can be considered to maximize the safety of the human worker. However, the accuracy and reliability of the system regarding system disturbances need to be justified.},
	language = {en},
	number = {1},
	urldate = {2020-04-21},
	journal = {Proceedings},
	author = {Tuli, Tadele Belay and Manns, Martin},
	year = {2019},
	note = {Number: 1
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {collaboration, HRC, human, motion tracking, robot},
	pages = {48},
	bibtex_show = True,
}

@article{manns_identifying_2021,
	series = {54th {CIRP} {CMS} 2021 - {Towards} {Digitalized} {Manufacturing} 4.0},
	title = {Identifying human intention during assembly operations using wearable motion capturing systems including eye focus},
	volume = {104},
	issn = {2212-8271},
	url = {https://www.sciencedirect.com/science/article/pii/S2212827121010532},
	doi = {10.1016/j.procir.2021.11.155},
	abstract = {Simulating human motion behavior in assembly operations helps to create efficient collaboration plans for humans and robots. However, identifying human intention may require high quality human motion capture data in order to discriminate micro-actions and human attention. In this regard, a human motion capture setup that combines various systems such as joint body, finger, and eye trackers is proposed in combination with a methodology of identifying the intention of human operators as well as for predicting sequences of activities. The approach may lead to safer human-robot collaboration.},
	language = {en},
	urldate = {2021-11-29},
	journal = {Procedia CIRP},
	author = {Manns, Martin and Tuli, Tadele Belay and Schreiber, Florian},
	month = jan,
	year = {2021},
	keywords = {human-robot collaboration, Operator 4.0, Eye tracker, human motion capture},
	pages = {924--929},
	bibtex_show = True,
	abbr={CIRP CMS},
	selected = True,
}


@article{tuli_hierarchical_2019,
	abbr={CIRP CMS},
	series = {52nd {CIRP} {Conference} on {Manufacturing} {Systems} ({CMS}), {Ljubljana}, {Slovenia}, {June} 12-14, 2019},
	title = {Hierarchical motion control for real time simulation of industrial robots},
	volume = {81},
	issn = {2212-8271},
	url = {http://www.sciencedirect.com/science/article/pii/S221282711930486X},
	doi = {10.1016/j.procir.2019.03.181},
	abstract = {Multi axis machine tools implement real time motion control algorithms. Objects including difficult to manufacture and deformable shapes show variable properties when tools apply a pressure on the object surface. Force compliant industrial robots are used to manipulate deformable objects in real time simulation. In this research, a hierarchical method of motion controlling strategy is presented. The proposed approach is described regarding performance characteristics such as accuracy, repeatability, controllability of the motion segmentation and time dynamics. The result shows that a hierarchical control approach can be considered as a potential candidate to manipulate deformable objects where force requirements are critical.},
	urldate = {2019-07-30},
	journal = {Procedia CIRP},
	author = {Tuli, Tadele Belay and Manns, Martin},
	month = jan,
	year = {2019},
	keywords = {hierarchical control, industrial robot, motion planning, realtime simulation},
	pages = {713--718},
	bibtex_show = True,
}

@inproceedings{tuli_mathematical_2018,
    abbr={ICAST},
	address = {Cham},
	series = {Lecture {Notes} of the {Institute} for {Computer} {Sciences}, {Social} {Informatics} and {Telecommunications} {Engineering}},
	title = {Mathematical {Modeling} and {Dynamic} {Simulation} of {Gantry} {Robot} {Using} {Bond} {Graph}},
	isbn = {978-3-319-95153-9},
	doi = {10.1007/978-3-319-95153-9_22},
	abstract = {This paper presents an initial mathematical modeling and dynamic simulation of gantry robot for the application of printing circuit on board. The classical modeling methods such as Newton-Euler, Kirchoff’s law and Lagrangian fails to unify both electrical and mechanical system models. Here, bond graph approach with robust trajectory planning which uses a blend of quadratic equations on triangular velocity profile is modeled in order to virtually simulate it. In this paper, the algebric mathematical models are developed using maple software. For the sake of simulation, the model is tested on matlab by integrating robot models which are developed by using Solidwork.},
	language = {en},
	booktitle = {Information and {Communication} {Technology} for {Development} for {Africa}},
	publisher = {Springer International Publishing},
	author = {Tuli, Tadele Belay},
	editor = {Mekuria, Fisseha and Nigussie, Ethiopia Enideg and Dargie, Waltenegus and Edward, Mutafugwa and Tegegne, Tesfa},
	year = {2018},
	keywords = {Robot, Bond graph, Dynamic simulation, Trajectory planning},
	pages = {228--237},
	bibtex_show = True,
}

@article{tuli_automated_2019,
	abbr={JMMP},
	title = {Automated {Unsupervised} {3D} {Tool}-{Path} {Generation} {Using} {Stacked} {2D} {Image} {Processing} {Technique}},
	volume = {3},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/2504-4494/3/4/84},
	doi = {10.3390/jmmp3040084},
	abstract = {Tool-path, feed-rate, and depth-of-cut of a tool determine the machining time, tool wear, power consumption, and realization costs. Before the commissioning and production, a preliminary phase of failure-mode identification and effect analysis allows for selecting the optimal machining parameters for cutting, which, in turn, reduces machinery faults, production errors and, ultimately, decreases costs. For this, scalable high-precision path generation algorithms requiring a low amount of computation might be advisable. The present work provides such a simplified scalable computationally low-intensive technique for tool-path generation. From a three dimensional (3D) digital model, the presented algorithm extracts multiple two dimensional (2D) layers. Depending on the required resolution, each layer is converted to a spatial image, and an algebraic analytic closed-form solution provides a geometrical tool path in Cartesian coordinates. The produced tool paths are stacked after processing all object layers. Finally, the generated tool path is translated into a machine code using a G-code generator algorithm. The introduced technique was implemented and simulated using MATLAB® pseudocode with a G-code interpreter and a simulator. The results showed that the proposed technique produced an automated unsupervised reliable tool-path-generator algorithm and reduced tool wear and costs, by allowing the selection of the tool depth-of-cut as an input.},
	language = {en},
	number = {4},
	urldate = {2021-02-07},
	journal = {Journal of Manufacturing and Materials Processing},
	author = {Tuli, Tadele Belay and Cesarini, Andrea},
	month = dec,
	year = {2019},
	note = {Number: 4
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {CAD/CAM, 3D modeling, G-code, image processing, tool path},
	pages = {84},
	bibtex_show = True,
}

@article{engel_roboterunterstutztes_2020,
	abbr={VDI-Z},
	title = {Roboterunterstütztes {Biegen} von {Verbundrohren}},
	volume = {162},
	issn = {0042-1766},
	url = {https://doi.org/10.37544/0042-1766-2020-12-49},
	doi = {10.37544/0042-1766-2020-12-49},
	abstract = {Das Biegen eines endlosfaserverstärkten, thermoplastischen
Verbundrohres mit Roboterunterstützung könnte die Effizienz des
Biegeprozesses und die Qualität des Endprodukts verbessern.
Nachfolgend wird die Kooperation von Robotern und Biegemaschinen beim Bearbeiten dieser Art von Rohren beschrieben.},
	language = {de},
	number = {12},
	urldate = {2021-03-03},
	journal = {VDI-Z},
	author = {Engel, Bernd and Manns, Martin and Tuli, Tadele Belay and Reuter, Jonas},
	year = {2020},
	pages = {49--51},
	bibtex_show = True,
}


@inproceedings{tuli_knowledge-based_2021,
	title = {Knowledge-{Based} {Digital} {Twin} for {Predicting} {Interactions} in {Human}-{Robot} {Collaboration}},
	doi = {10.1109/ETFA45728.2021.9613342},
	abstract = {Semantic representation of motions in a human-robot collaborative environment is essential for agile design and development of digital twins (DT) towards ensuring efficient collaboration between humans and robots in hybrid work systems, e.g., in assembly operations. Dividing activities into actions helps to further conceptualize motion models for predicting what a human intends to do in a hybrid work system. However, it is not straightforward to identify human intentions in collaborative operations for robots to understand and collaborate. This paper presents a concept for semantic representation of human actions and intention prediction using a flexible task ontology interface in the semantic data hub stored in a domain knowledge base. This semantic data hub enables the construction of a DT with corresponding reasoning and simulation algorithms. Furthermore, a knowledge-based DT concept is used to analyze and verify the presented use-case of Human-Robot Collaboration in assembly operations. The preliminary evaluation showed a promising reduction of time for assembly tasks, which identifies the potential to i) improve efficiency reflected by reducing costs and errors and ultimately ii) assist human workers in improving decision making. Thus the contribution of the current work involves a marriage of machine learning, robotics, and ontology engineering into DT to improve human-robot interaction and productivity in a collaborative production environment.},
	booktitle = {2021 26th {IEEE} {International} {Conference} on {Emerging} {Technologies} and {Factory} {Automation} ({ETFA} )},
	author = {Tuli, Tadele Belay and Kohl, Linus and Chala, Sisay Adugna and Manns, Martin and Ansari, Fazel},
	month = sep,
	year = {2021},
	keywords = {Collaboration, digital twin, Digital twin, human action models, human-robot interaction, Knowledge based systems, machine learning, Ontologies, ontology, Predictive models, Productivity, Semantics},
	pages = {1--8},
	abbr={IEEE ETFA},
	bibtex_show = True,
	selected = True,
	file = {2021130209.pdf},
}


@article{jonek_virtuelle_2021,
	abbr={wtOnline},
	title = {Virtuelle {Montageplanung} mit {Motion} {Capture} {Systemen}/{Virtual} assembly planning with motion capture systems},
	volume = {111},
	issn = {1436-4980},
	url = {https://elibrary.vdi-verlag.de/index.php?doi=10.37544/1436-4980-2021-04-78},
	doi = {10.37544/1436-4980-2021-04-78},
	abstract = {In der Planung von teilautomatisierten Montageprozessen ist ein wichtiges Ziel, nicht wertschöpfende Tätigkeiten wie Laufbewegungen zu vermeiden. Studien haben gezeigt, dass die tatsächlichen Laufbewegungen in Montageprozessen von den geplanten Bewegungen abweichen. Dieser Beitrag stellt eine Methode vor, tatsächliche Laufbewegungen mit Motion Capture zu erfassen und in die Laufwegsplanung einzubeziehen, sodass sich Prozess- und Arbeitsplatzgestaltung bereits frühzeitig optimieren lassen.
            \&nbsp;
            In planning of semi-automated assembly processes, an important aspect is to avoid non-value-adding activities such as walking movements. Studies have shown that the actual walking movements in assembly processes differ from the planned movements. This paper presents a method of capturing actual walking movements with motion capture and integrating them into walking path planning so that process and workplace design can be optimized at an early stage.},
	number = {04},
	urldate = {2021-05-21},
	journal = {wt Werkstattstechnik online},
	author = {Jonek, Michael and Manns, Martin and Tuli, Tadele Belay},
	year = {2021},
	pages = {256--259},
	bibtex_show = True,
}


@article{tuli_path_2021,
	abbr={CIRP CMS},
	series = {54th {CIRP} {CMS} 2021 - {Towards} {Digitalized} {Manufacturing} 4.0},
	title = {Path planning for simulating human motions in manual assembly operations},
	volume = {104},
	issn = {2212-8271},
	url = {https://www.sciencedirect.com/science/article/pii/S2212827121010544},
	doi = {10.1016/j.procir.2021.11.156},
	abstract = {Assembly operation simulation can e.g. be used for optimizing complex manual assembly processes in the automotive industry. However, realistic human motion modeling involves difficult tasks such as inserting objects that require constraint definitions and collision detection. In this work, a method that applies the concept of an optimized potential field is employed to generate a motion model unit for simulating human motion for the assembly of pedal cars. This motion model unit is implemented into the newly created MOSIM motion modeling interfaces that is currently being standardized. This approach may allow motion simulation without being tied to a specific 3D environment.},
	language = {en},
	urldate = {2021-11-29},
	journal = {Procedia CIRP},
	author = {Tuli, Tadele Belay and Manns, Martin and Zöller, Christian and Klein, Daniel},
	month = jan,
	year = {2021},
	keywords = {virtual reality, path planning, MOSIM, human motion simulation, motion model units, pedal cars, potential field},
	pages = {930--934},
	bibtex_show = True,
}


@article{frohn-sorensen_3d_2021,
	abbr={JAMT},
	title = {{3D} printed prototyping tools for flexible sheet metal drawing},
	issn = {1433-3015},
	url = {https://doi.org/10.1007/s00170-021-07312-y},
	doi = {10.1007/s00170-021-07312-y},
	abstract = {Due to the change from mass production to mass personalized production and the resulting intrinsic product flexibility, the automotive industry, among others, is looking for cost-efficient and resource-saving production methods to combining global just-in-time production. In addition to geometric manufacturing flexibility, additive manufacturing offers a resource-saving application for rapid prototyping and small series in predevelopment. In this study, the FDM process is utilized to manufacture the tooling to draw a small series of sheet metal parts in combination with the rubber pad forming process. Therefore, a variety of common AM polymer materials (PETG, PLA, and ABS) is compared in compression tests, from which PLA is selected to be applied as sheet metal forming die. For the rubber pad forming process, relevant processing parameters, i.e., press force and rubber cushion hardness, are studied with respect to forming depth. The product batch is examined by optical evaluation using a metrological system. The scans of the tool and sheet metal parts confirm the mechanical integrity of the additively manufactured die from polymer and thus the suitability of this approach for small series in sheet metal drawing processes, e.g., for automotive applications.},
	language = {en},
	urldate = {2021-05-31},
	journal = {The International Journal of Advanced Manufacturing Technology},
	author = {Frohn-Sörensen, Peter and Geueke, Michael and Tuli, Tadele Belay and Kuhnhen, Christopher and Manns, Martin and Engel, Bernd},
	month = may,
	year = {2021},
	bibtex_show = True,

}



@inproceedings{tuli_comparison_2022,
	address = {Cham},
	title = {Comparison of {AI}-based {Task} {Planning} {Approaches} for {Simulating} {Human}-{Robot} {Collaboration}},
	isbn = {978-3-030-90700-6},
	abstract = {Today, increased demands for personalized products are making human-robot collaborative tasks a focus of research mainly for improving production cycle time, precision, and accuracy. It is also required to simplify how human-robot tasks and motions are generated. A graphical flow control-based programming can be one of such methods. This work investigates whether the graphical approaches (e.g., using RAFCON) yield a better real-time simulation or not compared to agent approaches (e.g., using MOSIM-AJAN). This work may support the agility of the digital manufacturing process by enhancing the efficiency of human-robot collaboration.},
	booktitle = {Towards {Sustainable} {Customization}: {Bridging} {Smart} {Products} and {Manufacturing} {Systems}},
	publisher = {Springer International Publishing},
	author = {Tuli, Tadele Belay and Manns, Martin},
	editor = {Andersen, Ann-Louise and Andersen, Rasmus and Brunoe, Thomas Ditlev and Larsen, Maria Stoettrup Schioenning and Nielsen, Kjeld and Napoleone, Alessia and Kjeldgaard, Stefan},
	year = {2022},
	pages = {158--165},
	doi = {10.1007/978-3-030-90700-6_17},
	abbr={CIRP CARV},
}




@inproceedings{tuli_understanding_2022,
	abbr={CIRP CARV},
	award ={Best paper award},
	address = {Cham},
	series = {Lecture {Notes} in {Mechanical} {Engineering}},
	title = {Understanding {Shared} {Autonomy} of {Collaborative} {Humans} {Using} {Motion} {Capture} {System} for {Simulating} {Team} {Assembly}},
	isbn = {978-3-030-90700-6},
	doi = {10.1007/978-3-030-90700-6_59},
	abstract = {In virtual production planning, simulating human motions helps to improve process planning and interaction efficiency. However, simulating multiple humans sharing tasks in a shared workplace requires understanding how human workers interact and share autonomy. In this regard, an Inertial Measurement Unit based motion capture is employed for understanding shifting roles and learning effects. Parameters such as total time, distance, and acceleration variances in repetition are considered for modeling collaborative motion interactions. The results distinguish motion patterns versus the undertaken interactions. This work may serve as an initial input to model interaction schemes and recognize human actions behavior during team assembly. Furthermore, the concept can be extended toward a human-robot shared autonomy.},
	language = {en},
	booktitle = {Towards {Sustainable} {Customization}: {Bridging} {Smart} {Products} and {Manufacturing} {Systems}},
	publisher = {Springer International Publishing},
	author = {Tuli, Tadele Belay and Manns, Martin and Jonek, Michael},
	editor = {Andersen, Ann-Louise and Andersen, Rasmus and Brunoe, Thomas Ditlev and Larsen, Maria Stoettrup Schioenning and Nielsen, Kjeld and Napoleone, Alessia and Kjeldgaard, Stefan},
	year = {2022},
	keywords = {Human motion capture, Shared autonomy, Team interaction, Manual assembly, Role shifting},
	pages = {527--534},
	bibtex_show = True,
	selected = True,
	pdf = {shared_autonomy_final.pdf},
}




@inproceedings{jonek_constraints_2022,
	abbr={CIRP CARV},
	address = {Cham},
	series = {Lecture {Notes} in {Mechanical} {Engineering}},
	title = {Constraints for {Motion} {Generation} in {Work} {Planning} with {Digital} {Human} {Simulations}},
	isbn = {978-3-030-90700-6},
	doi = {10.1007/978-3-030-90700-6_64},
	abstract = {Flexible and varied manual assembly processes in the automotive industry are often based on manual labor. While simulation can be used to improve planning to maximize efficiency while minimizing ergonomic issues for workers, common simulation tools require extensive modeling time. In such simulations, the users are often process engineers who want to easily create complex human motion simulations. This paper presents a concept developed to create complex human motions for interacting with objects in a production environment with little effort. The concept separates between geometric constraints and the semantic meaning of the respective geometry. With a set of data types developed for this purpose based on a unified ontology, a range of geometric and semantic information can be specified for arbitrary objects. In this way, an action-specific motion generator can be used to define the appropriate motion for the interaction with an object depending on the action without defining case-specific constraints. For a first proof, the concept is tested and demonstrated in the assembly of a pedal car and sitting on a chair at a manual workstation. Based on the use case, the effect of effort reduction is shown.},
	language = {en},
	booktitle = {Towards {Sustainable} {Customization}: {Bridging} {Smart} {Products} and {Manufacturing} {Systems}},
	publisher = {Springer International Publishing},
	author = {Jonek, Michael and Tuli, Tadele Belay and Manns, Martin},
	editor = {Andersen, Ann-Louise and Andersen, Rasmus and Brunoe, Thomas Ditlev and Larsen, Maria Stoettrup Schioenning and Nielsen, Kjeld and Napoleone, Alessia and Kjeldgaard, Stefan},
	year = {2022},
	keywords = {Human motion simulation, Manufacturing simulation, Geometric constraints, Manufacturing planning, MOSIM},
	pages = {567--574},
	file = {constraint_final.pdf},
	bibtex_show = True,
}



@inproceedings{tuli_latentSpace_cms_2022,
	abbr={CIRP CMS},
	series = {55th CIRP CMS 2022 - Leading Manufacturing Systems Transformation},
	title = {Latent Space Based Collaborative Motion Modeling from Motion Capture Data for Human Robot Collaboration (accepted paper, Switzerland)},
	author = {Tuli, Tadele Belay and Henkel, Martin and Manns, Martin},
	year = {2022},
	journal = {Procedia CIRP},
	bibtex_show = True,
	selected = True,
}


@inproceedings{tuli_HARNets_2022,
	abbr={CPSL},
	author = {Tuli, Tadele Belay and Patel, Valay Mukesh  and Manns, Martin},
	booktitle = {CPSL 2022 - Conference On Production Systems And Logistics)},
	title = {Industrial Human Activity Prediction and Detection Using Sequential Memory Networks  (accepted paper, Canada)},
	year = {2022},
	bibtex_show = True,
	selected = True,
}







@book{tuli_finite_2012,
	abbr={M.Sc. Thesis},
	title = {Finite {Element} {Analysis} of {Bus} {Body} {Structures}: {Case} study at {Bishoftu} {Automotive} and {Locomotive} {Industry}, {Ethiopia} {Adama}, {Adama} {Science} and {Technology} {University} 2012},
	isbn = {978-3-659-25932-6},
	shorttitle = {Finite {Element} {Analysis} of {Bus} {Body} {Structures}},
	abstract = {Most of Automotive and Locomotive Industries lack the basic scientific methods like computer application to design and manufacture vehicle body structures in order to analyze static and dynamic loads effect. This work presents a finite element model of a city bus for both static and dynamic condition. Their effects are verified by using quarter car and half car multibody models. The basic finite element models are represented by a computer program with a graphic user interface using matlab environment. Designers and manufacturer’s can observe the responses of these models on different condition. This work, therefore introduces the mathematical models using a concept of finite element method to introduce how advanced modeling and analysis tools can be used for design and manufacturing of city bus body structures. Both vehicle industries and academic sectors can use this work as a further reference.},
	language = {English},
	publisher = {LAP LAMBERT Academic Publishing},
	author = {Tuli, Tadele Belay},
	month = oct,
	year = {2012},
	bibtex_show = True,

}


@thesis{tulimsc2,
	abbr={M.Sc. Thesis},
	author = {Tuli, Tadele Belay},
	year = {2015},
	title = {Task and path planning of industrial manipulator robot},
	url = {http://www5.unitn.it/Biblioteca/en/Web/TesiDocente/193537},
	bibtex_show = True,
}